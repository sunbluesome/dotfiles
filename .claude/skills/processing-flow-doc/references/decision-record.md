# 決定記録（Decision Record）テンプレート

AI生成コードの「なぜ」を記録し、理解負債を防ぐ。

## ADR形式

```markdown
### DR-{番号}: {決定タイトル}

**日付**: YYYY-MM-DD

**状況**:
何を決める必要があったか

**選択肢**:
1. {選択肢1}: {概要}
2. {選択肢2}: {概要}
3. {選択肢3}: {概要}

**決定**: {選んだ選択肢}

**理由**:
- {理由1}
- {理由2}
- {理由3}

**却下理由**:
- {選択肢1}: {なぜ却下したか}
- {選択肢2}: {なぜ却下したか}

**検証**:
{決定の正しさをどう検証したか}

**参照**:
- {関連ドキュメント}
- {参考文献}
```

## 決定カテゴリ

### アルゴリズム選択

```markdown
### DR-001: 予測モデルの選択

**状況**: 売上予測モデルの選定

**選択肢**:
1. Linear Regression: シンプル、解釈容易
2. Two-Stage GLM: ゼロ過多対応、解釈可能
3. XGBoost: 高精度、ブラックボックス
4. Neural Network: 高精度、解釈困難

**決定**: Two-Stage GLM

**理由**:
- 売上0が70%を占めるゼロ過多データに適合
- 係数から施策効果を定量的に説明可能
- 推論時間が短く運用に適する

**却下理由**:
- Linear Regression: ゼロ過多データで精度劣化
- XGBoost: 係数解釈ができずビジネス説明困難
- Neural Network: 過学習リスク、計算コスト

**検証**:
- CV RMSE比較: Two-Stage(0.23) < XGBoost(0.22) < Linear(0.31)
- 係数符号: ドメイン知識と100%一致
```

### 特徴量設計

```markdown
### DR-002: 時系列特徴量の設計

**状況**: 過去データからどの特徴量を生成するか

**選択肢**:
1. 単純ラグ: lag1, lag7, lag30
2. 移動平均: rolling7, rolling30
3. 差分: diff1, diff7
4. 全組み合わせ

**決定**: lag7 + rolling30 の組み合わせ

**理由**:
- 週次パターン: lag7で直近同曜日を捕捉
- トレンド: rolling30で月次傾向を捕捉
- 相関分析でこの2つが最も予測力が高い

**却下理由**:
- lag1: 高相関だがリークリスク
- diff: ノイズが増幅
- 全組み合わせ: 多重共線性

**検証**:
- VIF < 5 を確認
- 相関分析: `experiments/feature_analysis.ipynb`
```

### ハイパーパラメータ

```markdown
### DR-003: 正則化強度 alpha=0.1

**状況**: GLMの正則化パラメータ選定

**選定方法**:
- TimeSeriesSplit (5-fold)
- GridSearchCV

**探索範囲**: [0.001, 0.01, 0.1, 1.0, 10.0]

**結果**:
| alpha | CV RMSE | std | 備考 |
|-------|---------|-----|------|
| 0.001 | 0.28 | 0.03 | 過学習気味 |
| 0.01 | 0.25 | 0.02 | |
| **0.1** | **0.23** | **0.02** | **最小** |
| 1.0 | 0.26 | 0.02 | 過正則化 |
| 10.0 | 0.35 | 0.01 | 係数が過度に縮小 |

**決定**: alpha=0.1

**検証**:
- train/test gap < 10%
- 係数の符号がドメイン知識と一致
```

### アーキテクチャ

```markdown
### DR-004: Trainer/Predictor分離パターン

**状況**: モデルの学習と推論をどう設計するか

**選択肢**:
1. 単一クラス: fit/predictを同一クラスに
2. Trainer/Predictor分離: 責務を分割
3. 関数ベース: クラスを使わない

**決定**: Trainer/Predictor分離

**理由**:
- Trainer: 学習のみ、状態なし、副作用なし
- Predictor: 推論のみ、学習済みモデルを保持
- テスト容易性: 各責務を独立にテスト可能
- 運用: 学習と推論を別プロセスで実行可能

**却下理由**:
- 単一クラス: 責務が混在、テスト困難
- 関数ベース: 状態管理が複雑化
```

## 数式・理論の記録

```markdown
### DR-005: Two-Stage GLMの数理

**理論的背景**:

Two-Part Model (Mullahy, 1986) に基づく:

**Stage 1: 購入確率**
$$P(y > 0 | X) = \frac{1}{1 + e^{-X\beta_1}}$$

- リンク関数: logit
- 分布: Bernoulli

**Stage 2: 購入金額（条件付き）**
$$E[y | y > 0, X] = \exp(X\beta_2)$$

- リンク関数: log
- 分布: Gamma（正値連続）

**最終予測**:
$$\hat{y} = P(y > 0 | X) \times E[y | y > 0, X]$$

**前提条件**:
1. Stage 1とStage 2は独立に推定可能
2. $y > 0$ の条件付き分布がGamma族
3. 特徴量間の多重共線性がない (VIF < 5)

**参考文献**:
- Mullahy, J. (1986). "Specification and testing of some modified count data models"
- Manning, W. G., & Mullahy, J. (2001). "Estimating log models: to transform or not to transform?"
```

## 変更履歴の記録

```markdown
## 決定変更履歴

| DR | 日付 | 変更内容 | 理由 |
|----|------|---------|------|
| DR-001 | 2024-01-15 | 新規作成 | - |
| DR-001 | 2024-02-20 | XGBoostに変更 | 精度要件強化 |
| DR-003 | 2024-03-01 | alpha 0.1→0.05 | データ量増加 |
```
